<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE doc SYSTEM "doc.dtd">
<doc title="Installation Guide - Crunchy Containers for PostgreSQL">
<description>Installation Guide - Crunchy Containers for PostgreSQL</description>
<section id="_project_setup">
<title>Project Setup</title>
<p>The crunchy-containers can run on different environments including:</p>
<list>
<list-item>
<b>Docker 1.12</b>
</list-item>
<list-item>
<b>OpenShift Container Platform 3.6</b>
</list-item>
<list-item>
<b>Kubernetes 1.8+</b>
</list-item>
</list>
<p>In this document we list the basic installation steps required for these
environments.</p>
<p>These installation instructions are developed and tested for the following operating systems:</p>
<list>
<list-item>
<b>CentOS 7</b>
</list-item>
<list-item>
<b>RHEL 7</b>
</list-item>
</list>
<section id="_project_directory_structure">
<title>Project Directory Structure</title>
<p>First add the following lines to your .bashrc file to set
the project paths:</p>
<code-block>export GOPATH=$HOME/cdev
export GOBIN=$GOPATH/bin
export PATH=$PATH:$GOBIN
export CCP_BASEOS=centos7
export CCP_PGVERSION=10
export CCP_PG_FULLVERSION=10.3
export CCP_VERSION=1.8.1
export CCP_IMAGE_PREFIX=crunchydata
export CCP_IMAGE_TAG=$CCP_BASEOS-$CCP_PG_FULLVERSION-$CCP_VERSION
export CCPROOT=$GOPATH/src/github.com/crunchydata/crunchy-containers
export CCP_CLI=kubectl
export CCP_NAMESPACE=demo
export PV_PATH=/mnt/nfsfileshare
export LOCAL_IP=$(hostname --ip-address)
export REPLACE_CCP_IMAGE_PREFIX=crunchydata</code-block>
<p>It will be necessary to refresh your bashrc file in order for the changes to take
effect.</p>
<code-block>. ~/.bashrc</code-block>
<p>Next, set up a project directory structure and pull down the project:</p>
<code-block>mkdir $HOME/cdev $HOME/cdev/src $HOME/cdev/pkg $HOME/cdev/bin</code-block>
<p>At this point, if you are installing crunchy-containers on a CentOS 7 machine,
you may continue with the following instructions. If you are doing an installation
on RHEL 7, please view the instructions located
<link url="https://github.com/crunchydata/crunchy-containers/blob/master/docs/install.adoc#rhel-7">below</link>
that are specific to RHEL environments.</p>
<section id="_centos_7">
<title>CentOS 7</title>
<code-block>cd $GOPATH
sudo yum -y install golang git docker
go get github.com/tools/godep
cd src/github.com
mkdir crunchydata
cd crunchydata
git clone https://github.com/crunchydata/crunchy-containers
cd crunchy-containers
git checkout 1.8.1
go get github.com/blang/expenv</code-block>
<p><b>If you are a Crunchy enterprise customer, you will place the Crunchy repository
key and yum repository file into the $CCPROOT/conf directory at this point. These
files can be obtained through <link url="https://access.crunchydata.com/">https://access.crunchydata.com/</link> on the downloads
page.</b></p>
</section>
<section id="_rhel_7">
<title>RHEL 7</title>
<p>When setting up the environment on RHEL 7, there are slightly different steps that
need to be taken.</p>
<code-block>cd $GOPATH
sudo subscription-manager repos --enable=rhel-7-server-optional-rpms
sudo yum-config-manager --enable rhel-7-server-extras-rpms
sudo yum -y install git golang
go get github.com/tools/godep
cd src/github.com
mkdir crunchydata
cd crunchydata
git clone https://github.com/crunchydata/crunchy-containers
cd crunchy-containers
git checkout 1.8.1
go get github.com/blang/expenv</code-block>
<p><b>If you are a Crunchy enterprise customer, you will place the Crunchy repository
key and yum repository file into the $CCPROOT/conf directory at this point. These
files can be obtained through <link url="https://access.crunchydata.com/">https://access.crunchydata.com/</link> on the downloads
page.</b></p>
</section>
</section>
<section id="_creating_a_demo_namespace_on_kubernetes">
<title>Creating a Demo Namespace on Kubernetes</title>
<p>This section will illustrate how to set up a new Kubernetes namespace called <b>demo</b>, and will
then show how to provide permissions to that namespace to allow the Kubernetes examples to run
within that namespace. This is a <b>requirement</b> for running the examples.</p>
<p>First, view currently existing namespaces:</p>
<code-block>$ kubectl get namespace
NAME          STATUS    AGE
default       Active    21d
kube-public   Active    21d
kube-system   Active    21d</code-block>
<p>Then, create a new namespace called <b>demo</b>:</p>
<code-block>$ kubectl create -f $CCPROOT/conf/demo-namespace.json
namespace "demo" created
$ kubectl get namespace demo
NAME      STATUS    AGE
demo      Active    7s</code-block>
<p>Then we'll set the namespace as our current location:</p>
<code-block>$ kubectl config set-context $(kubectl config current-context) --namespace=demo</code-block>
<p>We can verify that the namespace was set correctly through the following command:</p>
<code-block>$ kubectl config view | grep namespace:
    namespace: demo</code-block>
</section>
<section id="_creating_a_demo_namespace_on_openshift">
<title>Creating a Demo Namespace on OpenShift</title>
<p>This section will illustrate how to set up a new OpenShift project called <b>demo</b>.
This is a <b>requirement</b> for running the examples.</p>
<p>First we will create a new project:</p>
<code-block>$ oc new-project demo --description="Crunchy Containers project" --display-name="Crunchy-Containers"
Now using project "demo" on server "https://127.0.0.1:8443".

You can add applications to this project with the 'new-app' command. For example, try:

    oc new-app centos/ruby-22-centos7~https://github.com/openshift/ruby-ex.git

to build a new example application in Ruby.</code-block>
<p>If we view the list of projects, we can see the new project has been added and is <quote>active</quote>.</p>
<code-block>$ oc get projects
NAME        DISPLAY NAME         STATUS
demo        Crunchy-Containers   Active
myproject   My Project           Active</code-block>
<p>If you were on a different project and wanted to switch to the demo project, you would do
so by running the following:</p>
<code-block>$ oc project demo
Now using project "demo" on server "https://127.0.0.1:8443".</code-block>
</section>
<section id="_installing_postgresql">
<title>Installing PostgreSQL</title>
<p>These installation instructions assume the installation of PostgreSQL 10
through the official PGDG repository. View the documentation located
<link url="https://wiki.postgresql.org/wiki/YUM_Installation">here</link> in
order to view more detailed notes or install a different version of PostgreSQL.</p>
<p>Locate and edit your distributions .repo file, located:</p>
<list>
<list-item>
On CentOS: /etc/yum.repos.d/CentOS-Base.repo, [base] and [updates] sections
</list-item>
<list-item>
On Red Hat: /etc/yum/pluginconf.d/rhnplugin.conf [main] section
</list-item>
</list>
<p>To the section(s) identified above, you need to append a line (otherwise
dependencies might resolve to the PostgreSQL supplied by the base repository):</p>
<code-block>exclude=postgresql*</code-block>
<p>Next, install the RPM relating to the base operating system and PostgreSQL version
you wish to install. The RPMs can be found <link url="https://yum.postgresql.org/repopackages.php">here</link>.</p>
<p>For example, to install PostgreSQL 10 on a CentOS 7 system:</p>
<code-block>sudo yum -y install https://download.postgresql.org/pub/repos/yum/10/redhat/rhel-7-x86_64/pgdg-centos10-10-2.noarch.rpm</code-block>
<p>Or to install PostgreSQL 10 on a RHEL 7 system:</p>
<code-block>sudo yum -y install https://download.postgresql.org/pub/repos/yum/testing/10/redhat/rhel-7-x86_64/pgdg-redhat10-10-2.noarch.rpm</code-block>
<p>You'll need to update your system:</p>
<code-block>sudo yum -y update</code-block>
<p>Then, go ahead and install the PostgreSQL server package.</p>
<code-block>sudo yum -y install postgresql10-server.x86_64</code-block>
</section>
</section>
<section id="_docker_environment">
<title>Docker Environment</title>
<p>As good practice, at this point you'll update your system.</p>
<code-block>sudo yum -y update</code-block>
<p>Now we'll install Docker.</p>
<code-block>sudo yum -y install docker</code-block>
<p>After that, it's necessary to add the <b>docker</b> group and give your user access
to that group (here referenced as <b>someuser</b>):</p>
<code-block>sudo groupadd docker
sudo usermod -a -G docker someuser</code-block>
<p>Remember to log out of the <b>someuser</b> account for the Docker group
to be added to your current session.  Once it's added, you'll be able
to run Docker commands from your user account.</p>
<code-block>su - someuser</code-block>
<p>You can ensure your <b>someuser</b> account is added correctly by running the following
command and ensuring <b>docker</b> appears as one of the results:</p>
<code-block>groups</code-block>
<p>Before you start Docker, you might consider configuring Docker storage:
This is described if you run:</p>
<code-block>man docker-storage-setup</code-block>
<p>Follow the instructions available <link url="https://docs.openshift.com/container-platform/3.4/install_config/install/host_preparation.html#configuring-docker-storage">on the main OpenShift documentation page</link>
to configure Docker storage appropriately.</p>
<p>These steps are illustrative of a typical process for setting up Docker storage. You will need to run these commands as root.</p>
<p>First, add an extra virtual hard disk to your virtual machine (see <link url="http://catlingmindswipe.blogspot.com/2012/02/how-to-create-new-virtual-disks-in.html">this blog post</link> for tips on how to do so).</p>
<p>Run this command to format the drive, where /dev/sd? is the new hard drive that was added:</p>
<code-block>fdisk /dev/sd?</code-block>
<p>Next, create a volume group on the new drive partition within the fdisk utility:</p>
<code-block>vgcreate docker-vg /dev/sd?</code-block>
<p>Then, you'll need to edit the docker-storage-setup configuration file in order to override default options. Add these two lines to <b>/etc/sysconfig/docker-storage-setup</b>:</p>
<code-block>DEVS=/dev/sd?
VG=docker-vg</code-block>
<p>Finally, run the command <b>docker-storage-setup</b> to use that new volume group. The results should state that the physical volume /dev/sd? and the volume group docker-vg have both been successfully created.</p>
<p>Next, we enable and start up Docker:</p>
<code-block>sudo systemctl enable docker.service
sudo systemctl start docker.service</code-block>
<p>Verify that Docker version 1.12.6 was installed, as per the OpenShift 3.6
<link url="https://docs.openshift.com/container-platform/3.6/install_config/install/host_preparation.html#installing-docker">requirements.</link></p>
<code-block>docker version</code-block>
<section id="_build_the_containers">
<title>Build the Containers</title>
<p>At this point, you have a decision to make - either download prebuilt
containers from <link url="https://hub.docker.com/">Dockerhub</link>, <b>or</b> build the containers on your local host.</p>
<p>To download the prebuilt containers, make sure you can login to
<link url="https://hub.docker.com/">Dockerhub</link>, and then run the following:</p>
<code-block>docker login
cd $CCPROOT
./bin/pull-from-dockerhub.sh</code-block>
<p>Or if you'd rather build the containers from source, perform a container
build as follows:</p>
<code-block>godep restore
cd $CCPROOT
make setup
make all</code-block>
<p>After this, you will have all the Crunchy containers built and are ready
for use in a <b>standalone Docker</b> environment.</p>
</section>
</section>
<section id="_configure_container_storage">
<title>Configure Container Storage</title>
<p>The Container Suite is tested on 3 different storage backends:</p>
<list>
<list-item>
hostPath (single node testing)
</list-item>
<list-item>
NFS (single and multi-node testing)
</list-item>
<list-item>
Gluster (dynamic storage on separate Gluster cluster)
</list-item>
</list>
<p>Other storage backends work as well including GCE, EBS, ScaleIO, and
others but may require you to modify various examples or configuration.</p>
<section id="_configure_hostpath">
<title>Configure HostPath</title>
<p>HostPath is the simplist storage backend to setup, it only is feasible
on a single node but is good for testing the examples.  You set
up <b>hostPath</b> storage as follows:</p>
<code-block>sudo mkdir /data
sudo chmod 777 /data
cd $CCPROOT/examples/pv
./create-pv.sh hostpath
./create-pvc.sh</code-block>
<p>This set of scripts will create 15 sample Persistent Volumes that
all point to <b>/data</b>.  It also creates sample Persistent Volume
Claims that can be shared by various examples because these
Volumes are created as ReadWriteMany.</p>
</section>
<section id="_configure_nfs_for_persistence">
<title>Configure NFS for Persistence</title>
<p>NFS is required for some of the examples, including the backup and restore
containers.</p>
<p>First, if you are running your NFS system with SELinux in enforcing mode, you will need to run the following command to allow NFS write permissions:</p>
<code-block>sudo setsebool -P virt_use_nfs 1</code-block>
<p>Detailed instructions that you can use for setting up a NFS server on Centos 7 are provided in the following link.</p>
<p><link url="http://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-setup-nfs-server-on-centos-7-rhel-7-fedora-22.html">http://www.itzgeek.com/how-tos/linux/centos-how-tos/how-to-setup-nfs-server-on-centos-7-rhel-7-fedora-22.html</link></p>
<admonition type="note">Most of the Crunchy containers run as the postgres UID (26), but you
will notice that when <b>supplementalGroups</b> are specified, the pod
will include the nfsnobody group in the list of groups for the pod user.</admonition>
<p>if you are running your client on a VM, you will need to
add <i>insecure</i> to the exportfs file on the NFS server due to the way port
translation is done between the VM host and the VM instance.</p>
<p>For more details on this bug, please see the following link.</p>
<p><link url="http://serverfault.com/questions/107546/mount-nfs-access-denied-by-server-while-mounting">http://serverfault.com/questions/107546/mount-nfs-access-denied-by-server-while-mounting</link></p>
<p>A suggested best practice for tuning NFS for PostgreSQL is to configure the PostgreSQL fstab
mount options like so:</p>
<code-block>proto=tcp,suid,rw,vers=3,proto=tcp,timeo=600,retrans=2,hard,fg,rsize=8192,wsize=8192</code-block>
<p>Network options:</p>
<code-block>MTU=9000</code-block>
<p>If interested in mounting the same NFS share multiple times on the same mount point,
look into the <link url="https://www.novell.com/support/kb/doc.php?id=7010210">noac mount option</link>.</p>
<p>Next, assuming that you are setting up NFS as your storage option, you
will need to run the following script:</p>
<code-block>cd $CCPROOT/examples/pv
./create-pv.sh nfs
./create-pvc.sh</code-block>
<admonition type="note">If you elect to configure HostPath or GCE as your storage option, please view
README.txt for command-line usage for the ./create-pv.sh command.</admonition>
</section>
<section id="_configure_gluster_for_persistence">
<title>Configure Gluster for Persistence</title>
<p>Setting up a Gluster cluster will offer you the ability to use
dynamic storage provisioning in the examples.  A set of example
Gluster configuration files is found at $CCPROOT/docs/gluster.</p>
<p>This configuration is for a 3 node Gluster cluster which runs
on a Centos7 Minimal VM deployment.  See <link url="https://github.com/CrunchyData/crunchy-containers/blob/master/docs/gluster/gluster-setup.adoc">https://github.com/CrunchyData/crunchy-containers/blob/master/docs/gluster/gluster-setup.adoc</link></p>
</section>
</section>
<section id="_openshift_environment">
<title>OpenShift Environment</title>
<p>See the OpenShift installation guide for details on how to install
OpenShift Enterprise on your host. The main instructions are here:</p>
<p><link url="https://docs.openshift.com/container-platform/3.6/install_config/install/quick_install.html">https://docs.openshift.com/container-platform/3.6/install_config/install/quick_install.html</link></p>
<admonition type="note">If you install OpenShift Enterprise on a server with less than <code>16GB</code> memory and <code>40GB</code>
of disk, the following Ansible variables need to be added to <code>~/.config/openshift/installer.cfg.yml</code>
prior to installation:</admonition>
<code-block>openshift_check_min_host_disk_gb: '10' # min 10gb disk
openshift_check_min_host_memory_gb: '3' # min 3gb memory</code-block>
</section>
<section id="_kubernetes_environment">
<title>Kubernetes Environment</title>
<p>See <link url="https://kubernetes.io/docs/setup/independent/install-kubeadm/">kubeadm</link>
for installing the latest version of Kubernetes.</p>
<section id="_helm_optional">
<title>Helm (optional)</title>
<p>Some Kubernetes Helm examples are provided in the following directory as one
option for deploying the Container Suite.</p>
<code-block>$CCPROOT/examples/helm/</code-block>
<p>Once you have your Kubernetes environment configured, it is simple to get
Helm up and running. Please refer to <link url="https://github.com/kubernetes/helm/blob/master/docs/install.md">this document</link>
to get Helm installed and configured properly.</p>
</section>
<section id="_dns">
<title>DNS</title>
<p>Please see <link url="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">here</link>
to view the official documentation regarding configuring DNS for your Kubernetes cluster.</p>
</section>
<section id="_google_cloud_environment">
<title>Google Cloud Environment</title>
<p>The PostgreSQL Container Suite was tested on Google Container Engine.</p>
<p>Here is a link to set up a Kube cluster on GCE:
<link url="https://kubernetes.io/docs/getting-started-guides/gce">https://kubernetes.io/docs/getting-started-guides/gce</link></p>
<p>Setup the persistent disks using GCE disks by first editing
your <b>bashrc</b> file and export the GCE settings to match your
GCE environment.</p>
<code-block>export GCE_DISK_ZONE=us-central1-a
export GCE_DISK_NAME=gce-disk-crunchy
export GCE_DISK_SIZE=4
export GCE_FS_FORMAT=ext4</code-block>
<p>Then create the PVs used by the examples, passing in the <b>gce</b>
value as a parameter. This will cause the GCE disks to be created:</p>
<code-block>cd $CCPROOT/examples/pv
./create-pv.sh gce
cd $CCPROOT/examples/pv
./create-pvc.sh</code-block>
<p>Here is a link that describes more information on GCE persistent disk:
<link url="https://cloud.google.com/container-engine/docs/tutorials/persistent-disk/">https://cloud.google.com/container-engine/docs/tutorials/persistent-disk/</link></p>
<p>To have the persistent disk examples work, you will need to specify
a <b>fsGroup</b> setting in the <b>SecurityContext</b> of each pod script
as follows:</p>
<code-block>       "securityContext": {
        "fsGroup": 26
        },</code-block>
<p>For our PostgreSQL container, a UID of 26 is specified as the user
which corresponds to the <b>fsGroup</b> value.</p>
</section>
<section id="_tips">
<title>Tips</title>
<p>Make sure your hostname resolves to a single IP address in your
/etc/hosts file. The NFS examples will not work otherwise and other problems
with installation can occur unless you have a resolving hostname.</p>
<p>You should see a single IP address returned from this command:</p>
<code-block>hostname --ip-address</code-block>
</section>
</section>
<section id="_legal_notices">
<title>Legal Notices</title>
<p>Copyright &amp;copy; 2018 Crunchy Data Solutions, Inc.</p>
<p>CRUNCHY DATA SOLUTIONS, INC. PROVIDES THIS GUIDE <quote>AS IS</quote> WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.</p>
<p>Crunchy, Crunchy Data Solutions, Inc. and the Crunchy Hippo Logo are trademarks of Crunchy Data Solutions, Inc.</p>
</section>
</doc>
