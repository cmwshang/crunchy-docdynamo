<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE doc SYSTEM "doc.dtd">
<doc title="Metrics Collection - Crunchy Containers for PostgreSQL">
<description>Metrics Collection - Crunchy Containers for PostgreSQL</description>
<section id="_metrics_collection">
<title>Metrics Collection</title>
<p>70 different PostgreSQL metrics are collected by the crunchy-collect container, which executes both the postgres_exporter and node_exporter. Written in Go, these are both metrics exporters that work with Prometheus to provide PostgreSQL server metrics in addition to hardware and OS metrics. The crunchy-collect container gathers different metrics from the crunchy-postgres PostgreSQL database container and pushes these to the Prometheus Promgateway.</p>
<p>The collector is similar to the Prometheus Pushgateway, in that it allows exporting of statistics from batch jobs. It can also be used to export static metrics, such as what role a machine has. These SQL metrics are pushed to the crunchy-promgateway container, which holds the Prometheus Promgateway. This container is then scraped by crunchy-prometheus which hosts Prometheus. Grafana runs from crunchy-grafana, which displays the collected PostgreSQL metrics from the crunchy-prometheus container as a data source and uses the metrics to build dashboards. The Grafana template used is defined by default using a JSON template and is indexed by Grafana as an accessible dashboard.</p>
<p>Prometheus is a multi-dimensional time series data model with an elastic query language. It is used in collaboration with Grafana in this metrics suite. Overall, it's reliable, manageable, and operationally simple for efficiently storing and analyzing data for large-scale environments. It targets the Promgateway as an endpoint for scraping metrics.</p>
<p>Grafana is open source, adaptable and efficient data conceptualization software. This technology is capable of converting raw data to beautifully represented graphs, allowing you to easily monitor your database with a glance. In addition, it has a strong query and transformation language that allows for instantaneous and complex combinations of metrics, queries, correlations, and mathematical graphing.</p>
<p>To start collection of metrics on a PostgreSQL database, you add the crunchy-collect container into the pod that holds the crunchy-postgres container.</p>
<code-block>|</code-block>
<section id="_overview">
<title>Overview</title>
<p>Metrics are stored in the crunchy-prometheus container, which runs the Prometheus time series database. It scrapes the crunchy-collect container which hosts the postgres_exporter and node_exporter for PostgreSQL server metrics as well as host and OS level metrics. These metrics are then pushed to crunchy-grafana in order to visualize the results.</p>
<p>The crunchy-prometheus data in this example is stored in emptyDir volume types. To persist the
data and Grafana templates long term, you will want to use NFS volume types as specified in
the script examples/openshift/metrics/run-pvc.sh.</p>
<p>When running crunchy-metrics, the following ports are available:</p>
<list>
<list-item>
<link url="http://crunchy-metrics:9090">http://crunchy-metrics:9090</link> - the Prometheus web user interface
</list-item>
<list-item>
<link url="http://crunchy-metrics:9091">http://crunchy-metrics:9091</link> - the Prometheus pushgateway REST API
</list-item>
<list-item>
<link url="http://crunchy-metrics:3000">http://crunchy-metrics:3000</link> - the Grafana web user interface
</list-item>
</list>
</section>
<section id="_environment_variables">
<title>Environment Variables</title>
<list>
<list-item>
PROM_GATEWAY - The HTTP URL of the Prometheus Pushgateway into which the metrics will be pushed
</list-item>
<list-item>
NODE_EXPORTER_URL - The HTTP URL of the node_exporter utility which collects host and OS level system metrics.
</list-item>
<list-item>
POSTGRES_EXPORTER_URL - The HTTP URL of the postgres_exporter utility which collects PostgreSQL server metrics.
</list-item>
<list-item>
DATA_SOURCE_NAME - The URL for the PostgreSQL server's data source name. This is <b>required</b> to be in the form of <b>postgresql://</b>.
</list-item>
</list>
</section>
<section id="_docker">
<title>Docker</title>
<p>You can collect various PostgreSQL metrics from your database container by running a
crunchy-collect container that points to your database container.</p>
<p>To start this set of containers, run the following:</p>
<code-block>cd $CCPROOT/examples/docker/metrics
./run.sh</code-block>
<p>This will start up 3 containers and services:</p>
<list>
<list-item>
<link url="http://crunchy-metrics:9090">http://crunchy-metrics:9090</link> - the Prometheus web user interface
</list-item>
<list-item>
<link url="http://crunchy-metrics:9091">http://crunchy-metrics:9091</link> - the Prometheus pushgateway REST API
</list-item>
<list-item>
<link url="http://crunchy-metrics:3000">http://crunchy-metrics:3000</link> - the Grafana web user interface
</list-item>
</list>
<p>An example has been provided that runs a database container
and also the associated metrics collection container, run the
example as follows:</p>
<code-block>cd $CCPROOT/examples/docker/collect
./run.sh</code-block>
<p>Every 3 minutes the collection container will collect PostgreSQL
metrics and push them to the Crunchy Prometheus database.  You
can graph them using the Crunchy Grafana container.</p>
<p>If firewalld is enabled in your environment, it may be necessary
to allow the necessary ports through the firewall. This can be
accomplished by the following:</p>
<code-block>firewall-cmd --permanent --new-zone metrics
firewall-cmd --permanent --zone metrics --add-port 9090/tcp
firewall-cmd --permanent --zone metrics --add-port 9091/tcp
firewall-cmd --permanent --zone metrics --add-port 3000/tcp
firewall-cmd --reload</code-block>
</section>
<section id="_kubernetes">
<title>Kubernetes</title>
<p>This example starts up Prometheus and Grafana.</p>
<p>It is required to view or capture metrics collected by crunchy-collect.</p>
<p>Running the example:</p>
<code-block>cd $CCPROOT/examples/kube/metrics
./run.sh</code-block>
<p>This will start up 3 containers and services:</p>
<list>
<list-item>
<link url="http://crunchy-metrics:9090">http://crunchy-metrics:9090</link> - the Prometheus web user interface
</list-item>
<list-item>
<link url="http://crunchy-metrics:9091">http://crunchy-metrics:9091</link> - the Prometheus pushgateway REST API
</list-item>
<list-item>
<link url="http://crunchy-metrics:3000">http://crunchy-metrics:3000</link> - the Grafana web user interface
</list-item>
</list>
<p>If you want your metrics and dashboards to persist to NFS, run
this script:</p>
<code-block>cd $CCPROOT/examples/kube/metrics
./run-pvc.sh</code-block>
<p>In the docs folder of the github repo, check out the metrics.adoc
for details on the exact metrics being collected.</p>
<p>This example runs a pod that includes a database container and
a metrics collection container. A service is also created for the pod.</p>
<p>Running the example:</p>
<code-block>cd $CCPROOT/examples/kube/collect
./run.sh</code-block>
<p>If firewalld is enabled in your environment, it may be necessary
to allow the necessary ports through the firewall. This can be
accomplished by the following:</p>
<code-block>firewall-cmd --permanent --new-zone metrics
firewall-cmd --permanent --zone metrics --add-port 9090/tcp
firewall-cmd --permanent --zone metrics --add-port 9091/tcp
firewall-cmd --permanent --zone metrics --add-port 3000/tcp
firewall-cmd --reload</code-block>
<p>You can view the collect container logs using this command:</p>
<code-block>kubectl logs -c collect primary-collect</code-block>
<p>You can access the database or drive load against it using
this command:</p>
<code-block>psql -h primary-collect -U postgres postgres</code-block>
</section>
<section id="_openshift">
<title>OpenShift</title>
<p>This example starts up Prometheus and Grafana.</p>
<p>It is required to view or capture metrics collected by crunchy-collect.</p>
<p>First, create the crunchy-metrics pod which contains
the Prometheus data store and the Grafana graphing web application:</p>
<code-block>cd $CCPROOT/examples/openshift/metrics
./run.sh</code-block>
<p>This will start up 3 containers and services:</p>
<list>
<list-item>
<link url="http://crunchy-metrics:9090">http://crunchy-metrics:9090</link> - the Prometheus web user interface
</list-item>
<list-item>
<link url="http://crunchy-metrics:9091">http://crunchy-metrics:9091</link> - the Prometheus pushgateway REST API
</list-item>
<list-item>
<link url="http://crunchy-metrics:3000">http://crunchy-metrics:3000</link> - the Grafana web user interface
</list-item>
</list>
<p>When accessing the Grafana web application, the default user credentials will be
the username <b>admin</b> and the password <b>admin</b>.</p>
<p>Next, start a PostgreSQL pod that has the crunchy-collect container
as follows:</p>
<code-block>cd $CCPROOT/examples/openshift/collect
./run.sh</code-block>
<p>At this point, metrics will be collected every 3 minutes and pushed
to Prometheus.  You can build graphs off the metrics using Grafana.</p>
<p>If firewalld is enabled in your environment, it may be necessary
to allow the necessary ports through the firewall. This can be
accomplished by the following:</p>
<code-block>firewall-cmd --permanent --new-zone metrics
firewall-cmd --permanent --zone metrics --add-port 9090/tcp
firewall-cmd --permanent --zone metrics --add-port 9091/tcp
firewall-cmd --permanent --zone metrics --add-port 3000/tcp
firewall-cmd --reload</code-block>
</section>
<section id="_node_exporter">
<title>node_exporter</title>
<p>The tables below list all existing collectors that are gathered by the <link url="https://github.com/prometheus/node_exporter">node_exporter</link>.
This tool collects hardware and OS level metrics exposed by the kernel as part of the crunchy-collect container.</p>
<p>This table lists all metrics collected by default with the node_exporter.</p>
<table>
<title label="Table 1. ">Enabled by Default</title>

<table-header>
<table-column align="left">Name</table-column>
<table-column align="left">Description</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>arp</table-cell>
<table-cell>Exposes ARP statistics from <code>/proc/net/arp</code>.</table-cell>
</table-row>
<table-row>
<table-cell>bcache</table-cell>
<table-cell>Exposes bcache statistics from <code>/sys/fs/bcache/</code>.</table-cell>
</table-row>
<table-row>
<table-cell>conntrack</table-cell>
<table-cell>Shows conntrack statistics (does nothing if no <code>/proc/sys/net/netfilter/</code> present).</table-cell>
</table-row>
<table-row>
<table-cell>cpu</table-cell>
<table-cell>Exposes CPU statistics</table-cell>
</table-row>
<table-row>
<table-cell>diskstats</table-cell>
<table-cell>Exposes disk I/O statistics.</table-cell>
</table-row>
<table-row>
<table-cell>edac</table-cell>
<table-cell>Exposes error detection and correction statistics.</table-cell>
</table-row>
<table-row>
<table-cell>entropy</table-cell>
<table-cell>Exposes available entropy.</table-cell>
</table-row>
<table-row>
<table-cell>exec</table-cell>
<table-cell>Exposes execution statistics.</table-cell>
</table-row>
<table-row>
<table-cell>filefd</table-cell>
<table-cell>Exposes file descriptor statistics from <code>/proc/sys/fs/file-nr</code>.</table-cell>
</table-row>
<table-row>
<table-cell>filesystem</table-cell>
<table-cell>Exposes filesystem statistics</table-cell>
</table-row>
<table-row>
<table-cell>hwmon</table-cell>
<table-cell>Expose hardware monitoring and sensor data from <code>/sys/class/hwmon/</code>.</table-cell>
</table-row>
<table-row>
<table-cell>infiniband</table-cell>
<table-cell>Exposes network statistics specific to InfiniBand and Intel OmniPath configurations.</table-cell>
</table-row>
<table-row>
<table-cell>ipvs</table-cell>
<table-cell>Exposes IPVS status from <code>/proc/net/ip_vs</code> and stats from <code>/proc/net/ip_vs_stats</code>.</table-cell>
</table-row>
<table-row>
<table-cell>loadavg</table-cell>
<table-cell>Exposes load average.</table-cell>
</table-row>
<table-row>
<table-cell>mdadm</table-cell>
<table-cell>Exposes statistics about devices in <code>/proc/mdstat</code> (does nothing if no <code>/proc/mdstat</code> present).</table-cell>
</table-row>
<table-row>
<table-cell>meminfo</table-cell>
<table-cell>Exposes memory statistics.</table-cell>
</table-row>
<table-row>
<table-cell>netdev</table-cell>
<table-cell>Exposes network interface statistics such as bytes transferred.</table-cell>
</table-row>
<table-row>
<table-cell>netstat</table-cell>
<table-cell>Exposes network statistics from <code>/proc/net/netstat</code>. This is the same information as <code>netstat -s</code>.</table-cell>
</table-row>
<table-row>
<table-cell>sockstat</table-cell>
<table-cell>Exposes various statistics from <code>/proc/net/sockstat</code>.</table-cell>
</table-row>
<table-row>
<table-cell>stat</table-cell>
<table-cell>Exposes various statistics from <code>/stat</code>. This includes boot time &amp; forks as well as interrupts.</table-cell>
</table-row>
<table-row>
<table-cell>textfile</table-cell>
<table-cell>Exposes statistics read from local disk. The <code>--collector.textfile.directory</code> flag must be set.</table-cell>
</table-row>
<table-row>
<table-cell>time</table-cell>
<table-cell>Exposes the current system time.</table-cell>
</table-row>
<table-row>
<table-cell>uname</table-cell>
<table-cell>Exposes system information as provided by the uname system call.</table-cell>
</table-row>
<table-row>
<table-cell>vmstat</table-cell>
<table-cell>Exposes statistics from <code>/proc/vmstat</code>.</table-cell>
</table-row>
<table-row>
<table-cell>wifi</table-cell>
<table-cell>Exposes WiFi device and station statistics.</table-cell>
</table-row>
<table-row>
<table-cell>xfs</table-cell>
<table-cell>Exposes XFS runtime statistics.</table-cell>
</table-row>
<table-row>
<table-cell>zfs</table-cell>
<table-cell>Exposes <link url="http://open-zfs.org/">ZFS</link> performance statistics.</table-cell>
</table-row>
</table-data>
</table>
<p>The following table contains metrics that are not enabled by default; these can be enabled using the <code>--collectors.enabled</code> flag.</p>
<table>
<title label="Table 2. ">Disabled by Default</title>

<table-header>
<table-column align="left">Name</table-column>
<table-column align="left">Description</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>bonding</table-cell>
<table-cell>Exposes the number of configured and active replicas of Linux bonding interfaces.</table-cell>
</table-row>
<table-row>
<table-cell>buddyinfo</table-cell>
<table-cell>Exposes statistics of memory fragments as reported by <code>/proc/buddyinfo</code>.</table-cell>
</table-row>
<table-row>
<table-cell>devstat</table-cell>
<table-cell>Exposes device statistics</table-cell>
</table-row>
<table-row>
<table-cell>drbd</table-cell>
<table-cell>Exposes Distributed Replicated Block Device statistics (to version 8.4)</table-cell>
</table-row>
<table-row>
<table-cell>interrupts</table-cell>
<table-cell>Exposes detailed interrupts statistics.</table-cell>
</table-row>
<table-row>
<table-cell>ksmd</table-cell>
<table-cell>Exposes kernel and system statistics from <code>/sys/kernel/mm/ksm</code>.</table-cell>
</table-row>
<table-row>
<table-cell>logind</table-cell>
<table-cell>Exposes session counts from <link url="http://www.freedesktop.org/wiki/Software/systemd/logind/">logind</link>.</table-cell>
</table-row>
<table-row>
<table-cell>meminfo\_numa</table-cell>
<table-cell>Exposes memory statistics from <code>/proc/meminfo_numa</code>.</table-cell>
</table-row>
<table-row>
<table-cell>mountstats</table-cell>
<table-cell>Exposes filesystem statistics from <code>/proc/self/mountstats</code>. Exposes detailed NFS client statistics.</table-cell>
</table-row>
<table-row>
<table-cell>nfs</table-cell>
<table-cell>Exposes NFS client statistics from <code>/proc/net/rpc/nfs</code>. This is the same information as <code>nfsstat -c</code>.</table-cell>
</table-row>
<table-row>
<table-cell>qdisc</table-cell>
<table-cell>Exposes <link url="https://en.wikipedia.org/wiki/Network_scheduler#Linux_kernel">queuing discipline</link> statistics</table-cell>
</table-row>
<table-row>
<table-cell>runit</table-cell>
<table-cell>Exposes service status from <link url="http://smarden.org/runit/">runit</link>.</table-cell>
</table-row>
<table-row>
<table-cell>supervisord</table-cell>
<table-cell>Exposes service status from <link url="http://supervisord.org/">supervisord</link>.</table-cell>
</table-row>
<table-row>
<table-cell>systemd</table-cell>
<table-cell>Exposes service and system status from <link url="http://www.freedesktop.org/wiki/Software/systemd/">systemd</link>.</table-cell>
</table-row>
<table-row>
<table-cell>tcpstat</table-cell>
<table-cell>Exposes TCP connection status information from <code>/proc/net/tcp</code> and <code>/proc/net/tcp6</code>. (Warning: the current version has potential performance issues in high load situations.)</table-cell>
</table-row>
</table-data>
</table>
<p>These metrics will be deprecated and (re)moved in future releases of node_exporter.</p>
<table>
<title label="Table 3. ">Deprecated</title>

<table-header>
<table-column align="left"> Name </table-column>
<table-column align="left"> Description</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>gmond</table-cell>
<table-cell>Exposes statistics from Ganglia.</table-cell>
</table-row>
<table-row>
<table-cell>megacli</table-cell>
<table-cell>Exposes RAID statistics from MegaCLI.</table-cell>
</table-row>
<table-row>
<table-cell>ntp</table-cell>
<table-cell>Exposes time drift from an NTP server.</table-cell>
</table-row>
</table-data>
</table>
</section>
<section id="_postgres_exporter">
<title>postgres_exporter</title>
<p>The <link url="https://github.com/wrouesnel/postgres_exporter">postgres_exporter</link> collects PostgreSQL server metrics as part of the crunchy-collect container.</p>
<p>The following are some general metrics it collects:</p>
<table>
<title label="Table 4. ">General</title>

<table-header>
<table-column align="left">Name</table-column>
<table-column align="left">Description</table-column>
<table-column align="left">Usage</table-column>
<table-column align="left">Query</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>pg_replication</table-cell>
<table-cell>Replication lag behind primary in seconds</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))::INT as lag</code></table-cell>
</table-row>
<table-row>
<table-cell>pg_postmaster</table-cell>
<table-cell>Time at which postmaster started</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()</code></table-cell>
</table-row>
</table-data>
</table>
<p>These metrics are general statistics on tables.</p>
<table>
<title label="Table 5. ">pg_stat_user_tables</title>

<table-header>
<table-column align="left">Name</table-column>
<table-column align="left">Description</table-column>
<table-column align="left">Usage</table-column>
<table-column align="left">Query</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>schemaname</table-cell>
<table-cell>Name of the schema that this table is in</table-cell>
<table-cell>LABEL</table-cell>
<table-cell><code>SELECT schemaname FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>relname</table-cell>
<table-cell>Name of this table</table-cell>
<table-cell>LABEL</table-cell>
<table-cell><code>SELECT relname FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>seq_scan</table-cell>
<table-cell>Number of sequential scans initiated on this table</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT seq_scan FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>seq_tup_read</table-cell>
<table-cell>Number of live rows fetched by sequential scans</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT seq_tup_read FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>idx_scan</table-cell>
<table-cell>Number of index scans initiated on this table</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT idx_scan FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>idx_tup_fetch</table-cell>
<table-cell>Number of live rows fetched by index scans</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT idx_tup_fetch FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_tup_ins</table-cell>
<table-cell>Number of rows inserted</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT n_tup_ins FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_tup_upd</table-cell>
<table-cell>Number of rows updated</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT n_tup_upd FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_tup_del</table-cell>
<table-cell>Number of rows deleted</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT n_tup_del FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_tup_hot_upd</table-cell>
<table-cell>Number of rows HOT updated (i.e. with no separate index update required)</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT n_tup_hot_upd FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_live_tup</table-cell>
<table-cell>Estimated number of live rows</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT n_live_tup FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_dead_tup</table-cell>
<table-cell>Estimated number of dead rows</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT n_dead_tup FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>n_mod_since_analyze</table-cell>
<table-cell>Estimated number of rows changed since last analyze</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT n_mod_since_analyze FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>last_vacuum</table-cell>
<table-cell>Last time at which this table was manually vacuumed (not counting VACUUM FULL)</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT last_vacuum FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>last_autovacuum</table-cell>
<table-cell>Last time at which this table was vacuumed by the autovacuum daemon</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT last_autovacuum FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>last_analyze</table-cell>
<table-cell>Last time at which this table was manually analyzed</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT last_analyze FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>last_autoanalyze</table-cell>
<table-cell>Last time at which this table was analyzed by the autovacuum daemon</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell><code>SELECT last_autoanalyze FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>vacuum_count</table-cell>
<table-cell>Number of times this table has been manually vacuumed (not counting VACUUM FULL)</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT vacuum_count FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>autovacuum_count</table-cell>
<table-cell>Number of times this table has been vacuumed by the autovacuum daemon</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT autovacuum_count FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>analyze_count</table-cell>
<table-cell>Number of times this table has been manually analyzed</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT analyze_count FROM pg_stat_user_tables</code></table-cell>
</table-row>
<table-row>
<table-cell>autoanalyze_count</table-cell>
<table-cell>Number of times this table has been analyzed by the autovacuum daemon</table-cell>
<table-cell>COUNTER</table-cell>
<table-cell><code>SELECT autoanalyze_count FROM pg_stat_user_tables</code></table-cell>
</table-row>
</table-data>
</table>
<p>These statistics provide database queries.</p>
<table>
<title label="Table 6. ">pg_database</title>

<table-header>
<table-column align="left">Name</table-column>
<table-column align="left">Description</table-column>
<table-column align="left">Usage</table-column>
<table-column align="left">Query</table-column>
</table-header>

<table-data>
<table-row>
<table-cell>datname</table-cell>
<table-cell>LABEL</table-cell>
<table-cell>Name of the database</table-cell>
<table-cell><code>SELECT pg_database.datname as size FROM pg_database</code></table-cell>
</table-row>
<table-row>
<table-cell>usage</table-cell>
<table-cell>GAUGE</table-cell>
<table-cell>Disk space used by the database</table-cell>
<table-cell><code>SELECT pg_database_size(pg_database.datname) as size FROM pg_database</code></table-cell>
</table-row>
</table-data>
</table>
</section>
<section id="_grafana_dashboard">
<title>Grafana Dashboard</title>
<p>Some information on creating custom Grafana dashboards can be found in the official documentation -
<link url="http://docs.grafana.org/guides/getting_started/">http://docs.grafana.org/guides/getting_started/</link>.</p>
<p>There is a sample dashboard included in the Metrics Suite which you can take advantage of instead of
creating a dashboard from scratch. The instructions provided below explain how to get started with using
the Grafana web interface and upload the dashboard for use.</p>
<p>The following instructions assume you already have the <b>crunchy-metrics</b> and <b>primary-collect</b> examples running
for your chosen environment.</p>
<p>Connect to the Grafana web instance using the following address:</p>
<code-block>http://crunchy-metrics:3000</code-block>
<p>The username and password are both <b>admin</b> by default. It is a recommended security measure to change these values.</p>
<p>After logging in, you'll be taken to a <quote>Home Dashboard</quote> page. Click <quote>add data source</quote>, where you'll be taken to
a page to populate your data source. In this instance, you'll want to select <quote>type</quote> as being <quote>Prometheus</quote> and change
the URL to point to <quote>http://localhost:9090</quote>. The screen should appear like this after you've finished:</p>
<code-block>|</code-block>
<p>Next, the dashboard needs to be imported as a JSON file. Navigate to the upper left corner and select the
Grafana logo for the menu, then to Dashboards &amp;rarr; Import. Select <quote>Upload JSON File</quote> and upload the following
JSON file:</p>
<code-block>$CCPROOT/conf/grafana/dashboards/PostgreSQL.json</code-block>
<p>The <quote>Import Datasource</quote> box should look similar to this before clicking <quote>Import</quote>:</p>
<code-block>|</code-block>
<p>The following images display the different metrics the included dashboard provides.</p>
<code-block>|</code-block>
<code-block>|</code-block>
<code-block>|</code-block>
</section>
</section>
<section id="_legal_notices">
<title>Legal Notices</title>
<p>Copyright &amp;copy; 2018 Crunchy Data Solutions, Inc.</p>
<p>CRUNCHY DATA SOLUTIONS, INC. PROVIDES THIS GUIDE <quote>AS IS</quote> WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESS OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE.</p>
<p>Crunchy, Crunchy Data Solutions, Inc. and the Crunchy Hippo Logo are trademarks of Crunchy Data Solutions, Inc.</p>
</section>
</doc>
